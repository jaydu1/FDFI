{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b13c0b60",
   "metadata": {},
   "source": [
    "# Quickstart: FDFI in 5 Minutes\n",
    "\n",
    "This tutorial introduces the basics of FDFI (Flow-Disentangled Feature Importance). By the end, you'll be able to:\n",
    "\n",
    "1. Create an explainer for any model\n",
    "2. Compute feature importance\n",
    "3. Interpret the results\n",
    "4. Get confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0216e9f",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd3b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dfi.explainers import OTExplainer\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe4f8e0",
   "metadata": {},
   "source": [
    "## Create a Simple Model\n",
    "\n",
    "Let's create a simple model where we know the true feature importance. Features 0 and 1 are important, the rest are noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8088eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X):\n",
    "    \"\"\"Simple model: y = x0 + 2*x1 + 0.5*x2\"\"\"\n",
    "    return X[:, 0] + 2 * X[:, 1] + 0.5 * X[:, 2]\n",
    "\n",
    "# Create training data (used as background distribution)\n",
    "n_samples = 200\n",
    "n_features = 10\n",
    "X_train = np.random.randn(n_samples, n_features)\n",
    "\n",
    "# Create test data to explain\n",
    "X_test = np.random.randn(20, n_features)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "print(f\"Model predictions for test data: {model(X_test)[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee95aea",
   "metadata": {},
   "source": [
    "## Create an Explainer\n",
    "\n",
    "The `OTExplainer` uses Gaussian optimal transport to compute feature importance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492ea9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the explainer\n",
    "explainer = OTExplainer(\n",
    "    model,              # The model to explain\n",
    "    data=X_train,       # Background data\n",
    "    nsamples=50,        # Monte Carlo samples per feature\n",
    ")\n",
    "\n",
    "print(\"Explainer created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c109f383",
   "metadata": {},
   "source": [
    "## Compute Feature Importance\n",
    "\n",
    "Call the explainer on test data to get feature importance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b8883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute feature importance\n",
    "results = explainer(X_test)\n",
    "\n",
    "# Print the results\n",
    "print(\"Feature Importance (phi_X):\")\n",
    "for i, phi in enumerate(results[\"phi_X\"]):\n",
    "    print(f\"  Feature {i}: {phi:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712787f5",
   "metadata": {},
   "source": [
    "## Interpret the Results\n",
    "\n",
    "The `results` dictionary contains:\n",
    "- `phi_X`: Feature importance in the original X-space\n",
    "- `phi_Z`: Feature importance in the disentangled Z-space\n",
    "- `se_X`, `se_Z`: Standard errors for uncertainty quantification\n",
    "\n",
    "Higher values indicate more important features. Since our model uses `x0 + 2*x1 + 0.5*x2`, we expect Features 0, 1, and 2 to have the highest importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018a1e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort features by importance\n",
    "importance = results[\"phi_X\"]\n",
    "sorted_idx = np.argsort(importance)[::-1]\n",
    "\n",
    "print(\"Features ranked by importance:\")\n",
    "for rank, idx in enumerate(sorted_idx):\n",
    "    print(f\"  Rank {rank+1}: Feature {idx} (importance = {importance[idx]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9949f90",
   "metadata": {},
   "source": [
    "## Get Confidence Intervals\n",
    "\n",
    "FDFI provides statistical inference via `conf_int()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a48247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confidence intervals\n",
    "ci = explainer.conf_int(\n",
    "    alpha=0.05,           # 95% confidence level\n",
    "    target=\"X\",           # Use X-space importance\n",
    "    alternative=\"greater\" # Test if importance > 0\n",
    ")\n",
    "\n",
    "print(\"\\nConfidence Intervals (95%, one-sided):\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Feature':>8} {'Estimate':>10} {'SE':>10} {'CI Lower':>10} {'P-value':>10}\")\n",
    "print(\"-\" * 60)\n",
    "for i in range(n_features):\n",
    "    sig = \"*\" if ci[\"reject_null\"][i] else \"\"\n",
    "    print(f\"{i:>8} {ci['phi_hat'][i]:>10.4f} {ci['se'][i]:>10.4f} \"\n",
    "          f\"{ci['ci_lower'][i]:>10.4f} {ci['pvalue'][i]:>10.4f} {sig}\")\n",
    "\n",
    "print(\"\\n* = significant at alpha=0.05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2740fb",
   "metadata": {},
   "source": [
    "## View Summary\n",
    "\n",
    "Use the built-in `summary()` method for a formatted output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23ce403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print formatted summary\n",
    "explainer.summary(alpha=0.05, alternative=\"greater\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9460f3",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you've learned the basics, check out these tutorials:\n",
    "\n",
    "- **OT Explainer Deep Dive**: Learn more about the Gaussian OT method\n",
    "- **EOT Explainer**: Entropic OT for non-Gaussian data\n",
    "- **Confidence Intervals**: Advanced statistical inference"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
